{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoreMorph\n",
    "\n",
    "\n",
    "In the basic algorithm, the graph fragments that make up the grammar are defined by a rootnode, a radius and a thickness. \n",
    "A fragment is called a $CIP_{radius}^{thickness}(root)$. The core is made up of all the nodes in a certain radius around the root. Interface part is \n",
    "the subgraph induced by every node in distance radius+thickness arround the root minus nodes in the core.\n",
    "\n",
    "\n",
    "Here, we generate a graph minor (by contracting edges) for any given input graph. We extract the CIP from the graph minor.  Due to the contraction \n",
    "one node in the minor may represent any number of nodes in the unaltered graph. \n",
    "once we have the core in the unaltered graph, we can consider all nodes in THICKNES distance to this core and obtain a new interface. \n",
    "\n",
    "Core and interface of the unaltered graph are saved in the grammar.\n",
    "There is still unused information in the interface of the minor graph. In the congruency check that will tell is if two CIPs are exchangeable, we not only check the unaltered graph interface but also the minor graphs interface. We hope that this will increase the score of the resulting applications of productions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialise nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from eden.util import configure_logging\n",
    "import logging\n",
    "\n",
    "DEBUG=False\n",
    "NJOBS=4\n",
    "if DEBUG: NJOBS=1\n",
    "\n",
    "configure_logging(logging.getLogger(),verbosity=1+DEBUG)\n",
    "from IPython.core.display import HTML\n",
    "HTML('<style>.container { width:95% !important; }</style>')\n",
    "\n",
    "# data source, see introduction for info.\n",
    "from eden.converter.graph.gspan import gspan_to_eden\n",
    "from itertools import islice\n",
    "def get_graphs(dataset_fname='../../toolsdata/bursi.pos.gspan', size=100):\n",
    "    return  islice(gspan_to_eden(dataset_fname),size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meet the GraphTransformer (and the decomposer)\n",
    "\n",
    "A graph transformer in general is used in two stages of the sampling process.\n",
    "First on an incoming graph to make it graphlearnable. Then, after a graph was changed, it might get \n",
    "retransformed.\n",
    "An example of this might be an RNA molecule that one wishes to refold after changing parts of the secondary structure graph.\n",
    "\n",
    "The decomposer is the interface between graphs and graphlearn.\n",
    "It is conducting substitutions of CIPs and extract CIPs from the graph.\n",
    "\n",
    "\n",
    "As long as the decomposer is delivering acceptable data, the sampler will not care what the graph looks like.\n",
    "It might not exist at all or have this second minorgraph version working in the background.\n",
    "\n",
    "\n",
    "### Data Defined Transformation\n",
    "In this first example, the graphminor generation is learned.\n",
    "We do this by using the (one class) estimator to annotate the nodes in the graph, then the graph is contracted\n",
    "on nodes with similar scores.\n",
    "The subgraphs obtained in this way are then clustered and the clustername is used for the names of the parts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '../../toolsdata/bursi.pos.gspan'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0d515b8720c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# the magic happens here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mdecomposers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmake_decomposer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_graphs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# lets look at some clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/martners/GraphLearn/graphlearn/minor/transform.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    289\u001b[0m         '''\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/martners/ike_EDeN/eden/converter/graph/gspan.pyc\u001b[0m in \u001b[0;36mgspan_to_eden\u001b[1;34m(input, options)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mstring_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'g'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m't'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/martners/ike_EDeN/eden/util/__init__.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(uri)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[1;31m# assume it is a file object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '../../toolsdata/bursi.pos.gspan'"
     ]
    }
   ],
   "source": [
    "from graphlearn.utils import selectdraw\n",
    "import graphlearn.minor.transform as transform\n",
    "import graphlearn.minor.decompose as decompose\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans \n",
    "import math\n",
    "#preparing\n",
    "make_decomposer = decompose.make_decomposergen(include_base=False, base_thickness_list=[2])\n",
    "\n",
    "# nodes in all graphs get scored.\n",
    "# the default functionality is to take all scores and cluster them \n",
    "# such that nodes that get assigned the same cluster can be contracted in a minor graph.\n",
    "# ShapeCluster is going the lazy route and uses the score of the node directly for the clusterid \n",
    "class ShapeCluster:\n",
    "    def fit(self,li):\n",
    "        pass\n",
    "    def predict(self,i):\n",
    "        return [math.ceil(i)]\n",
    "\n",
    "pp=transform.GraphMinorTransformer(#core_shape_cluster =KMeans(n_clusters=4),\n",
    "                                   core_shape_cluster =ShapeCluster(),\n",
    "                                   name_cluster       =MiniBatchKMeans(n_clusters=6), \n",
    "                                   save_graphclusters =True,\n",
    "                                   shape_score_threshold=2.5,\n",
    "                                   shape_min_size=2)\n",
    "\n",
    "\n",
    "\n",
    "# the magic happens here\n",
    "decomposers=[make_decomposer(pp.vectorizer,x) for x in pp.fit_transform(get_graphs(size=200))]\n",
    "\n",
    "# lets look at some clusters\n",
    "if False:\n",
    "    for cluster_id in pp.graphclusters:\n",
    "        print('cluster id: %d  num: %d' % (cluster_id, len(pp.graphclusters[cluster_id])))\n",
    "        if cluster_id != -1:\n",
    "            selectdraw(pp.graphclusters[cluster_id][:7], n_graphs_per_line=7, \n",
    "                            size=6, vertex_color='_label_', prog='neato', colormap='Set3',\n",
    "                            contract=False,edge_label='label')\n",
    "\n",
    "\n",
    "#lets draw what we did there\n",
    "for i in range(3):\n",
    "    selectdraw([decomposers[i+5].pre_vectorizer_graph(nested=True),decomposers[i+5].base_graph(),decomposers[i+5].abstract_graph()],\n",
    "                    size=10,\n",
    "                    contract=True, \n",
    "                    abstract_color='red',\n",
    "                    vertex_label='label',nesting_edge_alpha=0.7)\n",
    "\n",
    "    \n",
    "# confirming that cores of CIPs look interesting now:\n",
    "if False:\n",
    "    #parameters \n",
    "    radius_list=[0,2]\n",
    "    thickness_list=[2,4]\n",
    "    base_thickness_list=[2]\n",
    "    #extract\n",
    "    cips=decomposers[0].all_core_interface_pairs(thickness_list=[2],radius_list=[0,1],hash_bitmask=2**20-1)\n",
    "    draw.graphlearn([cips[0][0].graph,cips[0][1].graph], contract=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Defined GraphTransformer\n",
    "\n",
    "Here we see another example of a way to generate a graph minor.\n",
    "\n",
    "Since we are working on molecules, cyclic structures are of interest.\n",
    "Therefore it makes sense to introduce an abstraction based on these cycles.\n",
    "\n",
    "In this case the graph minor generation is not learned but boringly generated.\n",
    "\n",
    "\n",
    "##### notice how each cycle is contracted to one node in the minor graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from graphlearn.utils import draw\n",
    "import graphlearn.minor.molecule.transform_cycle as mole\n",
    "import graphlearn.minor.decompose as decompose\n",
    "from graphlearn.graphlearn import Sampler as GLS\n",
    "from eden.graph import Vectorizer\n",
    "\n",
    "\n",
    "\n",
    "make_decomposer = decompose.make_decomposergen(include_base=False, base_thickness_list=[2])\n",
    "\n",
    "#the preprocessor makes the abstraction, wrapper provides convenient format for drawing\n",
    "preproc=mole.GraphTransformerCircles()\n",
    "# get a graph and prepare it\n",
    "graphs=get_graphs()\n",
    "g=graphs.next()\n",
    "graph_wrapper=make_decomposer(preproc.vectorizer,preproc.wrap(g))\n",
    "graph=graph_wrapper.pre_vectorizer_graph(nested=True)\n",
    "\n",
    "# draw \n",
    "draw.graphlearn(graph,size=10, abstract_color='red', contract=True,ignore_for_layout='nesting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Generating a Sampler that uses GraphMinors\n",
    "\n",
    "There are no modifications made to the sampler.\n",
    "Just new decomposer and graphtransformer parameters are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from graphlearn.graphlearn import Sampler as graphlearn_sampler\n",
    "graphs = get_graphs(size=500)\n",
    "sampler=graphlearn_sampler(radius_list=[0,1],\n",
    "            thickness_list=[1], \n",
    "            min_cip_count=2, \n",
    "            min_interface_count=2, \n",
    "            decomposergen=make_decomposer,\n",
    "            graphtransformer=transform.GraphMinorTransformer(\n",
    "                                   core_shape_cluster =ShapeCluster(),\n",
    "                                   name_cluster       =MiniBatchKMeans(n_clusters=6), \n",
    "                                   save_graphclusters =True))\n",
    "\n",
    "sampler.fit(graphs,grammar_n_jobs=NJOBS)\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the induced grammar\n",
    "\n",
    "The first graph in each line shows the minor graph of the first CIP.\n",
    "note that the minor-interfacegraph is the same for all CIPs, while the minor-core might be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw.draw_grammar(sampler.lsgg.productions,n_productions=3,n_graphs_per_production=5,\n",
    "                     n_graphs_per_line=5, size=9, contract=False,\n",
    "                     colormap='Paired', invert_colormap=False,node_border=1,\n",
    "                     vertex_alpha=0.6, edge_alpha=0.5, node_size=450, abstract_interface=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample molecules\n",
    "\n",
    "Sampling works exactly the same way as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import graphlearn.utils.draw as draw\n",
    "import itertools\n",
    "\n",
    "#parameters\n",
    "graphs = get_graphs()\n",
    "id_start=15\n",
    "id_end=id_start+9\n",
    "graphs = itertools.islice(graphs,id_start,id_end)\n",
    "n_steps=50\n",
    "\n",
    "\n",
    "# sampling with many arguments.\n",
    "graphs = sampler.sample(graphs,\n",
    "                        n_samples=5,\n",
    "                        batch_size=1,\n",
    "                        n_steps=n_steps,\n",
    "                        n_jobs=1,\n",
    "                        quick_skip_orig_cip=False,\n",
    "                        probabilistic_core_choice=True,\n",
    "                        burnin=0,\n",
    "                        improving_threshold=0.5,\n",
    "                        select_cip_max_tries=100,\n",
    "                        keep_duplicates=True,\n",
    "                        include_seed=True)\n",
    "\n",
    " \n",
    "    \n",
    "scores=[]\n",
    "ids=range(id_start,id_end)\n",
    "for i,path_graphs in enumerate(graphs):\n",
    "    # for each sampling path:\n",
    "    print 'Graph id: %d'%(ids[i])\n",
    "    \n",
    "    #collect scores so that we can display the score graph later \n",
    "    scores.append(sampler.monitors[i].sampling_info['score_history'])\n",
    "    \n",
    "    # show graphs\n",
    "    if True:\n",
    "        draw.graphlearn(path_graphs,\n",
    "                        n_graphs_per_line=5, size=10, \n",
    "                       colormap='Paired', invert_colormap=False,node_border=0.5, vertex_color='_label_',\n",
    "                        vertex_alpha=0.5, edge_alpha=0.7, node_size=450)\n",
    "    else:\n",
    "        from graphlearn.utils import openbabel\n",
    "        openbabel.draw(path_graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot score graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "step=1\n",
    "num_graphs_per_plot=3\n",
    "num_plots=np.ceil([len(scores)/num_graphs_per_plot])\n",
    "for i in range(num_plots):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    for j,score in enumerate(scores[i*num_graphs_per_plot:i*num_graphs_per_plot+num_graphs_per_plot]):\n",
    "        data = list(islice(score,None, None, step))\n",
    "        plt.plot(data, label='graph %d'%(j+i*num_graphs_per_plot+id_start))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.ylim(-0.1,1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
