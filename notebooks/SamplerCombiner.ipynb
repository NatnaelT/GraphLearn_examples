{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Chaining Samplers\n",
    "\n",
    "A single sampler can optimise towards a single goal.\n",
    "If you chanin a lot of samplers you might be able to maximise towards multiple goals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialising logging,notebook and a way to obtain graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from eden.util import configure_logging\n",
    "import logging\n",
    "configure_logging(logging.getLogger(),verbosity=1)\n",
    "# get data\n",
    "from eden.converter.graph.gspan import gspan_to_eden\n",
    "from itertools import islice\n",
    "def get_graphs(dataset_fname, size=100):\n",
    "    return  islice(gspan_to_eden(dataset_fname),size)\n",
    "dataset_fname = '../toolsdata/bursi.pos.gspan'\n",
    "dataset_fname2 = '../toolsdata/bursi.neg.gspan'\n",
    "\n",
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training some samplers\n",
    "\n",
    "notice that sampler_b is trained on the negative set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from graphlearn.graphlearn import  Sampler\n",
    "from eden.graph import Vectorizer\n",
    "import traceback\n",
    "from graphlearn.localsubstitutablegraphgrammar import LocalSubstitutableGraphGrammar\n",
    "# get two samplers ready\n",
    "n_steps=30\n",
    "sampler_a=Sampler(grammar=LocalSubstitutableGraphGrammar(radius_list=[0,1], \n",
    "                thickness_list=[2],\n",
    "                min_cip_count=2, \n",
    "                min_interface_count=2),size_diff_core_filter=3,\n",
    "                    n_steps=n_steps,\n",
    "                    improving_threshold_fraction=.5,\n",
    "                    improving_linear_start_fraction=0.0,\n",
    "                    probabilistic_core_choice=False,\n",
    "                    score_core_choice=True)\n",
    "\n",
    "sampler_b=Sampler(grammar=LocalSubstitutableGraphGrammar(radius_list=[0,1], \n",
    "                thickness_list=[2],\n",
    "                min_cip_count=2, \n",
    "                min_interface_count=2),size_diff_core_filter=3,\n",
    "                    n_steps=n_steps,\n",
    "                    improving_threshold_fraction=.5,\n",
    "                    improving_linear_start_fraction=0.0,\n",
    "                    probabilistic_core_choice=False,\n",
    "                    score_core_choice=True)\n",
    "sampler_c=Sampler(grammar=LocalSubstitutableGraphGrammar(radius_list=[0,3], \n",
    "                thickness_list=[2],\n",
    "                min_cip_count=2, \n",
    "                min_interface_count=2),size_diff_core_filter=3,\n",
    "                    n_steps=n_steps,\n",
    "                    improving_threshold_fraction=.5,\n",
    "                    improving_linear_start_fraction=0.0,\n",
    "                    probabilistic_core_choice=False,\n",
    "                    score_core_choice=True)\n",
    "\n",
    "sampler_d=Sampler(grammar=LocalSubstitutableGraphGrammar(radius_list=[0,4], \n",
    "                thickness_list=[2],\n",
    "                min_cip_count=2, \n",
    "                min_interface_count=1),size_diff_core_filter=3,\n",
    "                    n_steps=n_steps,\n",
    "                    improving_threshold_fraction=.5,\n",
    "                    improving_linear_start_fraction=0.0,\n",
    "                    probabilistic_core_choice=False,\n",
    "                    score_core_choice=True)\n",
    "\n",
    "training_graphs = get_graphs(dataset_fname, size=200)\n",
    "sampler_a.fit(training_graphs)\n",
    "\n",
    "training_graphs_ii = get_graphs(dataset_fname2, size=200)\n",
    "sampler_b.fit(training_graphs_ii)\n",
    "\n",
    "'''\n",
    "training_graphs_iii = get_graphs(dataset_fname, size=100)\n",
    "sampler_c.fit(training_graphs_iii)\n",
    "training_graphs_iv = get_graphs(dataset_fname, size=100)\n",
    "sampler_d.fit(training_graphs_iv)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# combining samplers.\n",
    "\n",
    "Combining samplers is fairly simple. \n",
    "\n",
    "Most of the code below is spent setting up the data collecting monitors that give us a score history later.\n",
    "\n",
    "Thanks to a few lines of code in the graphlearn class, expressions like these are possible: \n",
    "samplercombiner((sampler_a+ sampler_b)-(sampler_b + sampler_c))\n",
    "\n",
    "Samplers dont have their own arguments (yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from graphlearn.utils.monitor import Monitor\n",
    "\n",
    "from graphlearn.trial_samplers.samplercombiner import samplercombiner\n",
    "'''\n",
    "class samplercombiner(object):\n",
    "    \n",
    "    def __init__(self,graphlearn):\n",
    "        self.parse(graphlearn)\n",
    "        \n",
    "    def getspawns(self, graphlearn):\n",
    "        \"\"\"\n",
    "        the graphsampler expression is like a tree.\n",
    "        we turn this into a list and make every graphlearner write into the same monitor object.\n",
    "        so taht we should be able to run all the sampler sequentially\n",
    "        \n",
    "        we also make graphlearn treat our injected monitor object with respect\n",
    "        \"\"\"\n",
    "        graphlearn._sample_init_init_monitor=lambda : 0\n",
    "        def f(s,g):\n",
    "            s.monitorobject.superscorelist.append(g._score)\n",
    "            s._score_list.append(g._score)\n",
    "        funcType = type(graphlearn._score_list_append)\n",
    "        graphlearn._score_list_append = funcType(f, graphlearn, Sampler)\n",
    "        \n",
    "        \n",
    "        li=[graphlearn]\n",
    "        for gl in graphlearn.__dict__.get('spawn_list',[]):\n",
    "            li+=self.getspawns(gl)\n",
    "        return li\n",
    "\n",
    "    \n",
    "    def parse(self,graphlearn):\n",
    "        self.learners=self.getspawns(graphlearn)\n",
    "        return self\n",
    "    \n",
    "    def what(self):\n",
    "        for e in self.learners:\n",
    "            print e.lsgg.radius_list, e.estimatorobject.inverse_prediction\n",
    "    \n",
    "    def fixmonitor(self, monitor,padlength):\n",
    "        \"\"\"\n",
    "        sampling may stop at any moment -> needs padding in monitor\n",
    "        \"\"\"\n",
    "        currentlen= len(monitor.superscorelist)\n",
    "        if currentlen == 0:\n",
    "            monitor.superscorelist.append(0)\n",
    "        monitor.superscorelist+= [monitor.superscorelist[-1]] * (padlength-currentlen)\n",
    "    \n",
    "    def run_single_graph(self,graph,repeats=2):\n",
    "        # set monitors:\n",
    "        monitor=Monitor(active=True)\n",
    "        monitor.superscorelist=[]\n",
    "        for sampler in self.learners:\n",
    "            sampler.monitorobject=monitor\n",
    "\n",
    "        # REPEAT times repeat the samplers in the list\n",
    "        n_steps=50\n",
    "        self.steps=n_steps*repeats*len(self.learners)\n",
    "        print self.steps\n",
    "        \n",
    "        for repeat in range(repeats):\n",
    "            for samplernum, sampler in enumerate(self.learners):\n",
    "                samplerresults = sampler.transform(\n",
    "                    graph_iter=[graph])\n",
    "                self.fixmonitor(sampler.monitorobject,repeat*len(self.learners)*n_steps+(samplernum)*n_steps)\n",
    "                graph=samplerresults.next()[0]\n",
    "        return graph,monitor\n",
    "\n",
    "        \n",
    "    def run_multi_graph(self,graphs,repeats=2):\n",
    "        for graph in graphs:\n",
    "            res=self.run_single_graph(graph,repeats=repeats)\n",
    "            # just hide the failures\n",
    "            if res != None:\n",
    "                yield res\n",
    "'''         \n",
    "#sc=samplercombiner((sampler_a+ sampler_b)-(sampler_b + sampler_c))\n",
    "#sc.what()\n",
    "sc=samplercombiner(sampler_a - sampler_b)\n",
    "sc.what()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample and show generated graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# RUN SAMPLER\n",
    "from itertools import islice\n",
    "graphs = get_graphs(dataset_fname, size=100)\n",
    "id_start=34\n",
    "id_end=id_start+6\n",
    "input_graphs = islice(graphs,id_start,id_end)\n",
    "results=sc.run_multi_graph(input_graphs,repeats=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Iterate sampler results, save information and show graphs\n",
    "from graphlearn.utils import selectdraw\n",
    "monitors=[]\n",
    "ids=range(id_start,id_end)\n",
    "for i,res in enumerate(results):\n",
    "    print 'Graph id: %d'%(ids[i])\n",
    "    monitors.append(res[1])\n",
    "    graphlist=res[0]\n",
    "    selectdraw(graphlist,contract=False,\n",
    "                   n_graphs_per_line=6, size=3, \n",
    "                   colormap='Paired', invert_colormap=False, vertex_color='_labels_',\n",
    "                   vertex_alpha=0.5, edge_alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores=[]               \n",
    "for mon in monitors: \n",
    "    scores.append( mon.superscorelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show sample score history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# plot sampling path score\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "SUMSTEPS=sc.steps\n",
    "markevery=5\n",
    "step=1\n",
    "num_graphs_per_plot=3\n",
    "num_plots=np.ceil([len(scores)/num_graphs_per_plot])\n",
    "for i in range(num_plots):\n",
    "\n",
    "    plt.figure(figsize=(13,5))\n",
    "    for j,score in enumerate(scores[i*num_graphs_per_plot:i*num_graphs_per_plot+num_graphs_per_plot]):\n",
    "     \n",
    "        data = list(islice(score,None, None, step))\n",
    "        plt.plot(data, linewidth=2, label='graph %d'%(j+i*num_graphs_per_plot+id_start))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.xlim(-1,SUMSTEPS+1)\n",
    "    plt.ylim(-0.1,1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
