{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We learn how to generate a graph minor on chemical structure graphs\n",
    "\n",
    "#### this time we use learned abstraction.   which means that we try to cluster the parts that get contracted in the minor and use the cluster_id as the name of a minor vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialise nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from eden.util import configure_logging\n",
    "import logging\n",
    "configure_logging(logging.getLogger(),verbosity=1)\n",
    "from IPython.core.display import HTML\n",
    "HTML('<style>.container { width:95% !important; }</style>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "from eden.converter.graph.gspan import gspan_to_eden\n",
    "from itertools import islice\n",
    "\n",
    "def get_graphs(dataset_fname='../toolsdata/bursi.pos.gspan', size=100):\n",
    "    return  islice(gspan_to_eden(dataset_fname),size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# demonstration of the preprocesor learning the abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from graphlearn.utils import draw\n",
    "import graphlearn.abstract_graphs.minortransform as transform\n",
    "import graphlearn.abstract_graphs.minordecompose as decompose\n",
    "from eden.graph import Vectorizer\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "#preparing\n",
    "v=Vectorizer(complexity=3)\n",
    "make_decomposer = lambda x,y: decompose.MinorDecomposer(x,y,\n",
    "                       include_base=False,\n",
    "                       base_thickness_list=[2])\n",
    "\n",
    "pp=transform.GraphTransformerMinorDecomp(core_shape_cluster=KMeans(n_clusters=4),\n",
    "                      name_cluster=MiniBatchKMeans(n_clusters=6), \n",
    "                      save_graphclusters=True)\n",
    "pp.set_param(v)\n",
    "\n",
    "# the magic happens here\n",
    "decomposers=[make_decomposer(v,x) for x in pp.fit_transform(get_graphs(size=100))]\n",
    "\n",
    "# lets look at some clusters\n",
    "for cluster_id in pp.graphclusters:\n",
    "    print('cluster id: %d  num: %d' % (cluster_id, len(pp.graphclusters[cluster_id])))\n",
    "    if cluster_id != -1:\n",
    "        draw.graphlearn(pp.graphclusters[cluster_id][:7], n_graphs_per_line=7, \n",
    "                        size=6, vertex_color='_label_', prog='neato', colormap='Set3',\n",
    "                        contract=False,edge_label='label')\n",
    "\n",
    "\n",
    "#lets draw what we did there\n",
    "for i in range(3):\n",
    "    draw.graphlearn([decomposers[i+5].pre_vectorizer_graph(),decomposers[i+5].base_graph(),decomposers[i+5].abstract_graph()],\n",
    "                    size=10,\n",
    "                    contract=True, \n",
    "                    abstract_color='red',\n",
    "                    vertex_label='label'\n",
    "                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets see if these wrappers give us CIPS as this is their only purpose.\n",
    "\n",
    "#### this is not interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#parameters \n",
    "radius_list=[0,2]\n",
    "thickness_list=[2,4]\n",
    "base_thickness_list=[2]\n",
    "#extract\n",
    "cips=decomposers[0].all_core_interface_pairs(thickness_list=[2],radius_list=[0,1],hash_bitmask=2**20-1)\n",
    "#draw\n",
    "draw.graphlearn(cips[0][0].graph, contract=False)\n",
    "draw.graphlearn(cips[0][1].graph, contract=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from graphlearn.graphlearn import Sampler as graphlearn_sampler\n",
    "graphs = get_graphs(size=200)\n",
    "sampler=graphlearn_sampler(radius_list=[0,1],\n",
    "            thickness_list=[1], \n",
    "            min_cip_count=2, \n",
    "            min_interface_count=2, \n",
    "            decomposer=make_decomposer,\n",
    "            graphtransformer=transform.GraphTransformerMinorDecomp(core_shape_cluster=KMeans(n_clusters=4),\n",
    "                                            name_cluster=MiniBatchKMeans(n_clusters=5),))\n",
    "\n",
    "sampler.fit(graphs,grammar_n_jobs=1)\n",
    "print 'done'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the induced grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw.draw_grammar(sampler.lsgg.productions,n_productions=5,n_graphs_per_production=5,\n",
    "                     n_graphs_per_line=5, size=9, contract=False,\n",
    "                     colormap='Paired', invert_colormap=False,node_border=1,\n",
    "                     vertex_alpha=0.6, edge_alpha=0.5, node_size=450, abstract_interface=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import graphlearn.utils.draw as draw\n",
    "import itertools\n",
    "from graphlearn.utils import openbabel\n",
    "#parameters\n",
    "graphs = get_graphs()\n",
    "id_start=15\n",
    "id_end=id_start+9\n",
    "graphs = itertools.islice(graphs,id_start,id_end)\n",
    "n_steps=50\n",
    "\n",
    "\n",
    "# sampling with many arguments.\n",
    "graphs = sampler.sample(graphs,\n",
    "                        n_samples=5,\n",
    "                        batch_size=1,\n",
    "                        n_steps=n_steps,\n",
    "                        n_jobs=1,\n",
    "                        quick_skip_orig_cip=False,\n",
    "                        probabilistic_core_choice=True,\n",
    "                        burnin=0,\n",
    "                        improving_threshold=0.5,\n",
    "                        select_cip_max_tries=100,\n",
    "                        keep_duplicates=True,\n",
    "                        include_seed=True)\n",
    "\n",
    " \n",
    "    \n",
    "scores=[]\n",
    "ids=range(id_start,id_end)\n",
    "for i,path_graphs in enumerate(graphs):\n",
    "    # for each sampling path:\n",
    "    print 'Graph id: %d'%(ids[i])\n",
    "    \n",
    "    #collect scores so that we can display the score graph later \n",
    "    scores.append(sampler.monitors[i].sampling_info['score_history'])\n",
    "    \n",
    "    # show graphs\n",
    "    #draw.graphlearn(path_graphs,\n",
    "    #                n_graphs_per_line=5, size=10, \n",
    "    #               colormap='Paired', invert_colormap=False,node_border=0.5, vertex_color='_label_',\n",
    "    #                vertex_alpha=0.5, edge_alpha=0.7, node_size=450)\n",
    "    openbabel.draw(path_graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot score graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "step=1\n",
    "num_graphs_per_plot=3\n",
    "num_plots=np.ceil([len(scores)/num_graphs_per_plot])\n",
    "for i in range(num_plots):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    for j,score in enumerate(scores[i*num_graphs_per_plot:i*num_graphs_per_plot+num_graphs_per_plot]):\n",
    "        data = list(islice(score,None, None, step))\n",
    "        plt.plot(data, label='graph %d'%(j+i*num_graphs_per_plot+id_start))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.ylim(-0.1,1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
